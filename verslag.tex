\documentclass[pdftex,12pt,a4paper]{article}
\usepackage[dutch]{babel}
\usepackage[pdftex]{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.markings,shapes}
\usepackage{array}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage{pgffor}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Matlab,                 % the language of the code
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
}

\pagestyle{fancy}
\lhead{Capita Selecta: Artifici\"ele Intelligentie}
\chead{Project}
\rhead{2013-2014}

\def\ci{\perp\!\!\!\perp}

\tikzset{
    every node/.style={
        circle,
        draw,
        inner sep     = 0pt,
        minimum width =20 pt
    }   
}  

\begin{document}

\begin{titlepage}

\begin{center}

\begin{flushleft}

\begin{tabular}{l|l}
\multirow{4}{*}{\includegraphics[scale=0.1]{KUL.jpg}} \\ & \\
& KATHOLIEKE UNIVERSITEIT LEUVEN\\[0.5cm]
& FACULTEIT INGENIEURSWETENSCHAPPEN\\
& \\
\end{tabular}\\[8cm]
\end{flushleft}



{\LARGE \textbf{Capita Selecta: Artifici\"ele Intelligentie}}\\[1cm]
\textbf{\LARGE Heuristieken}\\[8cm]


\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
Olivier \textsc{Deckers} \\
\end{flushleft}
\begin{flushleft} \large
Matthias \textsc{van der Hallen} \\
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
s0213127
\end{flushright}
\begin{flushright} \large
s0219692\\
\end{flushright}
\end{minipage}\\[1cm]

\end{center}

\end{titlepage}

\thispagestyle{empty}  
%\enlargethispage{10\baselineskip}
\setcounter{page}{0}
\newpage
\setcounter{page}{1}

\tableofcontents
\newpage

\section{Literatuurstudie}
Voor dit project werd eerst in de literatuur gezocht naar recente heuristieken voor het MDGP probleem. Hierbij werden vooral papers gevonden die gebruik maakten van de technieken \emph{tabu search}, \emph{simulated annealing} en \emph{variable neighbourhood search}.

In Palubeckis et al.\cite{Palubeckis} worden deze 3 methoden met elkaar vergeleken. Hieruit blijkt dat \emph{variable neighbourhood search} het effici\"entste was voor grotere problemen. Bovendien was deze methode voor ons beiden nog ongekend, in tegenstelling tot simulated annealing en genetic algorithms, waar we al ervaring mee hadden.

Daarom werd besloten dieper in te gaan op de \emph{variable neighbourhood search} methode. Hiervoor werd de paper van Urosevic\cite{Urosevic} gebruikt. Deze leek voornamelijk interessant door de veelbelovende resultaten en omdat de paper, in 2014 gepubliceerd, ook erg recent was. 

\section{GVNS}
De paper beschrijft een variant van variable neighbourhood search, genaamd general variable neighbourhood search (GVNS). Deze meta heuristiek bestaat uit drie componenten:

\begin{enumerate}
\item Greedy initial solution
\item Local search
\item Shaking
\item Random restarts
\end{enumerate}

In de volgende subsecties worden elk van deze componenten kort uitgelegd.

De pseudocode voor GVNS uit \cite{Urosevic} is terug te vinden in de appendix \ref{apx:gvns_pseudocode}. Deze pseudocode geeft aan hoe de componenten gecombineerd worden.

\subsection{Intensification}
\subsubsection{Greedy initial solution}
Een voor de hand liggende manier om een initi\"ele oplossing te genereren bestaat erin de elementen volledig willekeurig aan groepen toe te wijzen binnen de beperkingen van de grootte van deze groepen.

In de paper wordt er echter een greedy heuristiek gebruikt om de initi\"ele oplossing te genereren.
Elementen worden een voor een toegewezen aan de groep waarvoor de gemiddelde afstand van de elementen die al aan de groep toegewezen zijn tot het element maximaal is.

\subsubsection{Local search}
Als local search methode wordt variable neighbourhood descent gebruikt.

De paper omschrijft drie verschillende neighbourhood structuren: \emph{insertion}, \emph{swap} en \emph{3-chain}.

\begin{description}
\item[Insertion] Insertion werkt door een element van een groep die meer dan zijn minimum aantal elementen bevat te verplaatsen naar een andere groep, die minder dan zijn maximum aantal elementen bevat.
\item[Swap] Swap werkt door twee elementen uit verschillende groepen met elkaar om te wisselen.
\item[3-Chain] De 3-chain methode kiest willekeurig 3 elementen $i, j, k$ uit 3 verschillende groepen $g_{i}, g_{j}, g_{k}$. Vervolgens wordt element $i$ in groep $g_{j}$ geplaatst, element $j$ in groep $g_{k}$ en element $k$ in groep $g_{i}$.
\end{description}

Uit de experimenten in de paper blijkt dat de uitvoeringstijd van variable neighbourhood descent stijgt met een factor 150 wanneer 3-chain gebruikt wordt. 
De resulterende oplossingen blijken maar 1.7 keer beter te zijn.
Om deze reden worden enkel insertion en swap gebruikt. 

De tijd die gespaard wordt door 3-chain uit te schakelen kan vermoedelijk nuttiger aangewend worden door meerdere random restarts uit te voeren.

\subsection{Diversification}
\subsubsection{Shaking}
Als diversificatie stelt de paper een shaking procedure voor.
Deze procedure bestaat erin $k$ willekeurige swaps uit te voeren op de huidige oplossing. 
De parameter $k$ is een parameter van de procedure, die door GVNS bepaald wordt.

\subsubsection{Random restarts}
Verder implementeert de paper van Urosevic\cite{Urosevic} ook random restarts. Indien een betere oplossing niet gevonden wordt met VNS, wordt er een nieuwe initi\"ele oplossing gegenereerd met de greedy heuristiek die opnieuw geoptimaliseerd wordt.

In dit opzicht is het wel belangrijk dat de greedy heuristiek een willekeurige component bevat en niet deterministisch steeds dezelfde oplossing teruggeeft.

\section{Nabeschouwing van het artikel}
De gebruikte paper geeft een goede inleiding tot het probleem en introduceert duidelijk de verschillende componenten van hun oplossing, namelijk de greedy initial solution, variable neighbourhood descent, shaking en random restarts.
Een kleine fout in een formule nagelaten zijn ook de wiskundige onderbouwing en de code van de verschillende onderdelen duidelijk.

Wanneer deze verschillende onderdelen gecombineerd worden zijn echter niet altijd alle keuzes gespecificeerd.
Zo zijn er verschillende mogelijke manieren om de neighbourhood structuren te combineren tot een variable neighbourhood descent.

Deze verschillen in het aantal keer dat elke structuur de kans gegeven wordt om verbetering op te leveren en de greedyness van de descent. Het is namelijk mogelijk om de structuur toe te passen zodra hij verbetering oplevert, maar er kan ook gekozen worden om de structuur meerdere keren te testen en vervolgens de beste verbetering in gebruik te nemen.

Deze verschillende opties kunnen een grote invloed hebben op de kwaliteit van de gevonden oplossing.

De methodologie gebruikt bij het testen, hoeveel tijd en samples elke test kreeg en de parameters van variable neighbourhood search die hierbij gebruikt werden, zijn wel erg duidelijk vermeld.

Op deze methodologi\"en zijn wel enkele opmerkingen te maken. Zo wordt de keuze tussen \emph{random initial solution} en \emph{greedy initial solution} gemotiveerd door deze 2 methoden een oplossing te laten genereren en deze vervolgens door \'e\'en enkele iteratie van \emph{variable neighbourhood descent} te laten optimaliseren. 
Hierbij kan men echter in twijfel trekken of de betere startwaarde die greedy initial solutions geven  geen oneerlijk voordeel geven aan deze methode. Het is namelijk goed mogelijk dat juist deze betere startwaarden zich in een lokaal optimum bevinden, waar meerdere iteraties van \emph{variable neighbourhood descent}, zelfs indien geholpen door een shake operator, niet uitgeraken. Daarom werd besloten deze keuze later opnieuw te onderzoeken.

\section{Implementatie}
Zoals eerder vermeld laat de paper na de exacte implementatie van hun variable neighbourhood descent te beschrijven. Voornamelijk bij het samenstellen van alle verschillende neighbourhood structuren tot variable neighbourhood descent is hierdoor veel keuzevrijheid overgelaten aan de implementator.

Hierbij werd gekozen om zo nauw mogelijk bij de variable neighbourhood descent te blijven zoals omschreven in de les. Dit betekent dat de kleinste neighbourhood, insertion, 10 kansen gegeven werd om een verbetering op te leveren.
De eerste verbetering gevonden binnen deze 10 kansen werd doorgevoerd en insertion kreeg opnieuw 10 kansen.

Indien er geen verbetering gevonden werd in 10 tries, dan wordt verder gegaan met 10 tries voor de swap neighbourhood structure. Opnieuw wordt greedy de eerste verbetering toegepast, waarna opnieuw iteration gebruikt wordt.

Als ook swap geen verbetering vindt, dan stopt variable neighbourhood descent en geeft het best gevonden resultaat terug.
\\[1em]
Bij het implementeren van de verschillende neighbourhood structuren werd er bovendien op gelet dat de effici\"ente $\delta$-updates, beschreven in de paper,gebruikt werden. Hierdoor moeten deze fitness values niet telkens opnieuw berekend worden.

\\[1em]
Ook bij het implementeren van de greedy initial solution moesten bepaalde designkeuzes gemaakt worden. Zoals eerder vermeld moet deze methode nog altijd randomness introduceren, zoniet zou elke random restart vanaf dezelfde initial solution vertrekken.
 
Bij het genereren van een initial solution is het mogelijk om randomness te introduceren door niet altijd de beste group te nemen, of door de volgorde waarin de elementen toegevoegd worden aan de beste groep willekeurig te maken. Beide opties introduceren variatie in de initial solution die gebruikt wordt bij random restarts. De paper kiest hier voor de 2de optie. In de \emph{sectie \ref{sec:Resultaten}} zullen we ook de optie beschouwen om volledig random initial solution te gebruiken.
 
\section{Resultaten \label{sec:Resultaten}}
Doordat het algoritme een tijdslimiet heeft, hangen de resultaten sterk af van de machine waarop ze berekend zijn. Snellere machines zullen meer iteraties kunnen doorlopen in dezelfde tijd. Daarom is het ook moeilijk om de resultaten rechtstreeks te vergelijken met deze uit de paper.

Alle resultaten werden berekend op dezelfde machine met een 2.3 GHz Intel Core i7 (Haswell).


\subsection{Initial solution}
Het experiment uit de paper om het effect van de initi\"ele oplossing te onderzoeken houdt houdt rekening met de fitness na \'e\'en keer de local search methode toe te passen op de initi\"ele oplossing.

Zoals hierboven vermeld zijn deze resultaten zijn echter niet zomaar door te trekken naar het gebruik van de heuristiek in GVNS, waar het gebruik van uitsluitend greedy initial solutions mogelijk een te sterke beperking vormt op de zoekruimte om een optimale oplossing te vinden.

Daarom werd ervoor gekozen om het effect van de initi\"ele oplossing te onderzoeken wanneer het volledige algoritme doorlopen wordt. De resultaten hiervan zijn terug te vinden in tabel \ref{table:greedyvsrandom}.

In tegenstelling tot wat de paper aanneemt, blijkt uit deze resultaten dat het gebruik van een willekeurige initi\"ele oplossing tot een hogere fitness leidt.

\begin{table}
\centering
\begin{tabular}{l|c|c|c|c}
& \multicolumn{3}{c|}{Fitness} & Time\\
& Min & Gem & Max & (ms) \\\hline
Random & 1311449.558 &	1315008.215 &	1317348.628 &	600701.3333\\
Greedy & 1022540.472 & 1028084.531 &	1030556.030 &	608098.3333
\end{tabular}
\caption{Vergelijking van de resultaten voor greedy versus willekeurige initi\"ele oplossingen. Resultaten werden berekend op de  RanReal\_n960\_ds\_10.txt benchmark dataset en over zes runs uitgemiddeld.}
\label{table:greedyvsrandom}
\end{table}

\subsection{VND-3 vs VND-2}
De paper vergelijkt deze twee local search operatoren los van de rest van het algoritme op basis van de kwaliteit van de oplossing en de tijd die nodig was om ze te genereren.

Omdat VND-3 maar een licht betere oplossing kon vinden en hiervoor veel meer tijd nodig had (zie ook eerder), werd de 3-chain operator uitgeschakeld voor de rest van de experimenten.

In dit experiment wordt onderzocht of de tijdswinst door het uitschakelen van 3-chain ook effectief opweegt tegen de lagere kwaliteit van oplossingen die uit de local search methode komen.
Dit wordt getest door het algoritme met en zonder 3-chain te laten lopen. De resultaten zijn te vinden in tabel \ref{table:vnd3vsvnd2}.

Het aantal iteraties is inderdaad significant lager wanneer 3-chain aanstaat, en het blijkt dat het effici\"enter is om meer iteraties te doorlopen dan in een uitgebreidere neighbourhood te zoeken: de resulterende fitnesses zijn hoger wanneer de 3-chain operator uitstaat.


\begin{table}[h]
\centering
\begin{tabular}{l|c|c|c|c|c}
& \multicolumn{3}{c|}{Fitness} & Time & Iteraties \\
& Min & Gem & Max & (ms) & Gem \\\hline 
VND-3 & 1268020.326	& 1278367.001 & 1294208.466	& 641090.3333 & 23.50\\
VND-2 & 1311449.558 &	1315008.215 &	1317348.628 &	600701.333 & 400.33
\end{tabular}
\caption{Vergelijking van de resultaten voor VND-2 en VND-3. De resultaten werden berekend op de RanReal\_n960\_ds\_10.txt, met random initial solution en uitgemiddeld over zes runs.}
\label{table:vnd3vsvnd2}
\end{table}

\section{Real World Voorbeeld}

Het maximally diverse grouping probleem kan terug gevonden worden in het vormen van groepen researchers voor de peer review die gebeurt bij publicatie van een paper. Het doel van de peer review stap is het waarborgen van de kwaliteit van verschillende papers. Hierbij is het belangrijk om zoveel mogelijk verscheidenheid te behouden bij het kiezen van de reviewers, om zo reviewers uit verschillende velden van expertise en uit verschillende opleidingen en universiteiten de paper te laten nalezen.

Om MDGP te gebruiken bij het kiezen van peer reviewers is een preprocessing stap nodig die de matrix van afstanden tussen de verschillende onderzoekers opstelt. Het is mogelijk om hierbij te kijken naar de thuis-universiteit en het expertise gebied van elk van de reviewers. Hoe meer de thuis-universiteiten geografisch of methodologisch bij elkaar horen, hoe kleiner de afstand tussen de researchers in de afstandsmatrix. Op het vlak van expertise ligt de zaak iets moeilijk. Het is natuurlijk van belang om te zorgen dat elke reviewer tenminste een zekere mate aan basiskennis heeft over het onderwerp van de te reviewen paper. Dit kan bereikt worden door te vertrekken van papers met min of meer het zelfde vakgebied.

De definitie van het MDGP probleem staat ons ook toe om te bepalen hoeveel reviewers er minimum en maximum aan elke paper toegekend mogen worden. 

\newpage
\begin{thebibliography}{9}
\bibitem{Palubeckis}
  G. Palubeckis et al.
  \emph{Comparative performance of three metaheuristic approaches
for the maximally diverse grouping problem}.
  Information Technology And Control, 2011, Vol 40, No 4.
  
\bibitem{Urosevic}
 D. Urosevic
 \emph{Variable Neighborhood search for maximum diverse grouping problem}.
 Yugoslav Journal of Operations Research, 2014, Vol 24.

\end{thebibliography}

\newpage
\section{Appendices}
\begin{figure}[h]
\begin{verbatim}
program GVNS(xopt, kmin, kmax, kstep, tmax, nrest)
    x := InitialSolution;
    x := VND(x);
    xopt := x;
    k := kmin;
    niter := 0;
    while RunningTime < tmax do
      x' := Shake(x, k);
      x'' := VND(x')
      if f(x'') > f(x) then
        x := x''; k := kmin;
      else
        k := k + kstep;
        if k > kmax then
          niter := niter+1;
          if niter = nrest then
            if f(x) > f(xopt) then xopt := x;
            x := InitialSolution;
            niter := 0;
          endif
          k := kmin;
        endif
      endif
    endwhile
\end{verbatim}
\caption{GVNS pseudocode (uit \cite{Urosevic})}
\label{apx:gvns_pseudocode}
\end{figure}
\end{document}